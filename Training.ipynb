{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:47:44.844817Z","iopub.status.busy":"2024-04-14T09:47:44.844559Z","iopub.status.idle":"2024-04-14T09:48:39.524608Z","shell.execute_reply":"2024-04-14T09:48:39.523510Z","shell.execute_reply.started":"2024-04-14T09:47:44.844794Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n","chex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\n","ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install trl  accelerate git+https://github.com/huggingface/peft.git -Uqqq\n","!pip install einops wandb -Uqqq"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:48:39.526891Z","iopub.status.busy":"2024-04-14T09:48:39.526551Z","iopub.status.idle":"2024-04-14T09:49:02.356658Z","shell.execute_reply":"2024-04-14T09:49:02.355528Z","shell.execute_reply.started":"2024-04-14T09:48:39.526864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.38.2\n","  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (2.31.0)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.4.1 (from transformers==4.38.2)\n","  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2023.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.2) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2) (2023.7.22)\n","Installing collected packages: safetensors, tokenizers, transformers\n","  Attempting uninstall: safetensors\n","    Found existing installation: safetensors 0.3.3\n","    Uninstalling safetensors-0.3.3:\n","      Successfully uninstalled safetensors-0.3.3\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.33.0\n","    Uninstalling transformers-4.33.0:\n","      Successfully uninstalled transformers-4.33.0\n","Successfully installed safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.2\n"]}],"source":["!pip install transformers==4.38.2"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:02.358252Z","iopub.status.busy":"2024-04-14T09:49:02.357952Z","iopub.status.idle":"2024-04-14T09:49:13.499689Z","shell.execute_reply":"2024-04-14T09:49:13.498206Z","shell.execute_reply.started":"2024-04-14T09:49:02.358225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: transformers\n","Version: 4.38.2\n","Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n","Home-page: https://github.com/huggingface/transformers\n","Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n","Author-email: transformers@huggingface.co\n","License: Apache 2.0 License\n","Location: /opt/conda/lib/python3.10/site-packages\n","Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n","Required-by: peft, trl\n"]}],"source":["!pip show transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:13.503860Z","iopub.status.busy":"2024-04-14T09:49:13.503346Z","iopub.status.idle":"2024-04-14T09:49:31.013103Z","shell.execute_reply":"2024-04-14T09:49:31.012162Z","shell.execute_reply.started":"2024-04-14T09:49:13.503803Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Collecting datasets\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.12.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Collecting pyarrow>=12.0.0 (from datasets)\n","  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, pyarrow, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 11.0.0\n","    Uninstalling pyarrow-11.0.0:\n","      Successfully uninstalled pyarrow-11.0.0\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.1.0\n","    Uninstalling datasets-2.1.0:\n","      Successfully uninstalled datasets-2.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\n","beatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","ibis-framework 6.2.0 requires pyarrow<13,>=2, but you have pyarrow 15.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.18.0 pyarrow-15.0.2 pyarrow-hotfix-0.6\n"]}],"source":["!pip install -U datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:31.014928Z","iopub.status.busy":"2024-04-14T09:49:31.014546Z","iopub.status.idle":"2024-04-14T09:49:47.290477Z","shell.execute_reply":"2024-04-14T09:49:47.289376Z","shell.execute_reply.started":"2024-04-14T09:49:31.014872Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple/\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.0.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.23.5)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n"]}],"source":["!pip install -i https://pypi.org/simple/ bitsandbytes  #newline "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:47.292087Z","iopub.status.busy":"2024-04-14T09:49:47.291772Z","iopub.status.idle":"2024-04-14T09:49:59.079427Z","shell.execute_reply":"2024-04-14T09:49:59.078290Z","shell.execute_reply.started":"2024-04-14T09:49:47.292057Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install accelerate  "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T09:48:50.201545Z","iopub.status.busy":"2024-04-02T09:48:50.201244Z","iopub.status.idle":"2024-04-02T09:48:50.206139Z","shell.execute_reply":"2024-04-02T09:48:50.205251Z","shell.execute_reply.started":"2024-04-02T09:48:50.201517Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:59.081491Z","iopub.status.busy":"2024-04-14T09:49:59.081113Z","iopub.status.idle":"2024-04-14T09:50:12.801938Z","shell.execute_reply":"2024-04-14T09:50:12.801170Z","shell.execute_reply.started":"2024-04-14T09:49:59.081454Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import torch\n","import glob\n","import pandas as pd\n","import numpy as np\n","import re\n","from peft import get_peft_model, PeftConfig, PeftModel, LoraConfig, prepare_model_for_kbit_training\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, GenerationConfig\n","from trl import SFTTrainer\n","from datasets import Dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T09:49:02.692194Z","iopub.status.busy":"2024-04-02T09:49:02.691474Z","iopub.status.idle":"2024-04-02T09:49:02.696308Z","shell.execute_reply":"2024-04-02T09:49:02.695396Z","shell.execute_reply.started":"2024-04-02T09:49:02.692165Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:53:35.455882Z","iopub.status.busy":"2024-04-14T09:53:35.454957Z","iopub.status.idle":"2024-04-14T09:53:35.461936Z","shell.execute_reply":"2024-04-14T09:53:35.461169Z","shell.execute_reply.started":"2024-04-14T09:53:35.455845Z"},"trusted":true},"outputs":[],"source":["quantization_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_quant_type=\"nf4\",bnb_4bit_use_double_quant=False, bnb_4bit_compute_dtype=torch.bfloat16)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:53:35.937597Z","iopub.status.busy":"2024-04-14T09:53:35.937227Z","iopub.status.idle":"2024-04-14T09:53:38.175638Z","shell.execute_reply":"2024-04-14T09:53:38.174623Z","shell.execute_reply.started":"2024-04-14T09:53:35.937564Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"Salesforce/codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/pytorch_model.bin\n","/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Instantiating CodeGenForCausalLM model under default dtype torch.float16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 50256\n","}\n","\n","target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n","All model checkpoint weights were used when initializing CodeGenForCausalLM.\n","\n","All the weights of CodeGenForCausalLM were initialized from the model checkpoint at Salesforce/codegen-350M-mono.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use CodeGenForCausalLM for predictions without further training.\n","Generation config file not found, using a generation config created from the model config.\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/merges.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/tokenizer.json\n","loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/added_tokens.json\n","loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/tokenizer_config.json\n"]}],"source":["\n","\n","model_name = \"Salesforce/codegen-350M-mono\"\n","\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=quantization_config, \n","    device_map=\"auto\",  \n","    trust_remote_code=True,\n","    \n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True) \n","#tokenizer.pad_token = tokenizer.eos_token  # modification"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T09:49:23.069203Z","iopub.status.busy":"2024-04-02T09:49:23.068890Z","iopub.status.idle":"2024-04-02T09:49:23.073300Z","shell.execute_reply":"2024-04-02T09:49:23.072425Z","shell.execute_reply.started":"2024-04-02T09:49:23.069177Z"},"trusted":true},"outputs":[],"source":["#model_name = \"facebook/opt-350m\"\n","#tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True) \n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:42:19.751758Z","iopub.status.busy":"2024-04-04T06:42:19.751355Z","iopub.status.idle":"2024-04-04T06:42:19.758175Z","shell.execute_reply":"2024-04-04T06:42:19.757190Z","shell.execute_reply.started":"2024-04-04T06:42:19.751725Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1000000000000000019884624838656"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:53:53.418053Z","iopub.status.busy":"2024-04-14T09:53:53.417660Z","iopub.status.idle":"2024-04-14T09:53:53.422500Z","shell.execute_reply":"2024-04-14T09:53:53.421534Z","shell.execute_reply.started":"2024-04-14T09:53:53.418021Z"},"trusted":true},"outputs":[],"source":["if tokenizer.model_max_length > 100_000:\n","  tokenizer.model_max_length = 2048"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:37:03.354102Z","iopub.status.busy":"2024-04-04T06:37:03.353742Z","iopub.status.idle":"2024-04-04T06:37:03.358755Z","shell.execute_reply":"2024-04-04T06:37:03.357806Z","shell.execute_reply.started":"2024-04-04T06:37:03.354074Z"},"trusted":true},"outputs":[],"source":["if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T09:18:52.161868Z","iopub.status.busy":"2024-04-02T09:18:52.161571Z","iopub.status.idle":"2024-04-02T09:18:52.171087Z","shell.execute_reply":"2024-04-02T09:18:52.170111Z","shell.execute_reply.started":"2024-04-02T09:18:52.161843Z"},"trusted":true},"outputs":[],"source":["DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n","tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:39:27.471637Z","iopub.status.busy":"2024-04-04T06:39:27.470844Z","iopub.status.idle":"2024-04-04T06:39:31.567412Z","shell.execute_reply":"2024-04-04T06:39:31.566516Z","shell.execute_reply.started":"2024-04-04T06:39:27.471582Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2452b95ae24746e6a4966eebfe8e31b7","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/905 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b52bcc3803c84de785cf7d2862bb60f2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ab7ae73cf494fa48b8dc8ef6be2ea00","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/18612 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'input', 'output', 'prompt'],\n","        num_rows: 18612\n","    })\n","})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","#dataset = load_dataset(\"daily_dialog\")\n","#dataset = dataset.remove_columns([\"act\", \"emotion\"])\n","dataset = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\")\n","dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:39:41.014357Z","iopub.status.busy":"2024-04-04T06:39:41.013442Z","iopub.status.idle":"2024-04-04T06:39:41.019926Z","shell.execute_reply":"2024-04-04T06:39:41.019010Z","shell.execute_reply.started":"2024-04-04T06:39:41.014320Z"},"trusted":true},"outputs":[],"source":["def format_instruction(data):\n","    processed_data = []\n","    for sample in data:\n","        \n","        data = f\"\"\"Instruction:\n","        Use the Task below and the Input given to write the Response, which is a programming code that can solve the following Task:\n","\n","        ### Task:\n","        {sample['instruction']}\n","\n","        ### Input:\n","        {sample['input']}\n","\n","        ### Response:\n","        {sample['output']}\n","        \"\"\"\n","        processed_data.append(data)\n","    return pd.DataFrame({\"inputs\": processed_data})\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:44:26.712666Z","iopub.status.busy":"2024-04-04T06:44:26.711683Z","iopub.status.idle":"2024-04-04T06:44:27.873896Z","shell.execute_reply":"2024-04-04T06:44:27.872899Z","shell.execute_reply.started":"2024-04-04T06:44:26.712604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  inputs\n","0      Instruction:\\n        Use the Task below and t...\n","1      Instruction:\\n        Use the Task below and t...\n","2      Instruction:\\n        Use the Task below and t...\n","3      Instruction:\\n        Use the Task below and t...\n","4      Instruction:\\n        Use the Task below and t...\n","...                                                  ...\n","18607  Instruction:\\n        Use the Task below and t...\n","18608  Instruction:\\n        Use the Task below and t...\n","18609  Instruction:\\n        Use the Task below and t...\n","18610  Instruction:\\n        Use the Task below and t...\n","18611  Instruction:\\n        Use the Task below and t...\n","\n","[18612 rows x 1 columns]\n","                                                  inputs\n","8546   Instruction:\\n        Use the Task below and t...\n","5250   Instruction:\\n        Use the Task below and t...\n","6315   Instruction:\\n        Use the Task below and t...\n","16096  Instruction:\\n        Use the Task below and t...\n","10643  Instruction:\\n        Use the Task below and t...\n","...                                                  ...\n","11284  Instruction:\\n        Use the Task below and t...\n","11964  Instruction:\\n        Use the Task below and t...\n","5390   Instruction:\\n        Use the Task below and t...\n","860    Instruction:\\n        Use the Task below and t...\n","15795  Instruction:\\n        Use the Task below and t...\n","\n","[18612 rows x 1 columns]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11470</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>15254</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>10040</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>4858</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>8580</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11284</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>11964</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>5390</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>15795</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>611 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                  inputs\n","11470  Instruction:\\n        Use the Task below and t...\n","15254  Instruction:\\n        Use the Task below and t...\n","10040  Instruction:\\n        Use the Task below and t...\n","4858   Instruction:\\n        Use the Task below and t...\n","8580   Instruction:\\n        Use the Task below and t...\n","...                                                  ...\n","11284  Instruction:\\n        Use the Task below and t...\n","11964  Instruction:\\n        Use the Task below and t...\n","5390   Instruction:\\n        Use the Task below and t...\n","860    Instruction:\\n        Use the Task below and t...\n","15795  Instruction:\\n        Use the Task below and t...\n","\n","[611 rows x 1 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["#train_ds = preprocess_function(dataset['train'], tokenize=False, add_generation_prompt=False)\n","#train_ds = preprocess_function_chatalpaca(dataset['train'], tokenize=False, add_generation_prompt=False)\n","train_ds = format_instruction(dataset['train'])\n","print(train_ds)\n","train_ds = train_ds.sample(frac = 1)\n","print(train_ds)\n","test_ds = train_ds[18001:]\n","train_ds = train_ds[0:18001]\n","test_ds"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:44:35.052254Z","iopub.status.busy":"2024-04-04T06:44:35.051350Z","iopub.status.idle":"2024-04-04T06:44:35.062209Z","shell.execute_reply":"2024-04-04T06:44:35.061337Z","shell.execute_reply.started":"2024-04-04T06:44:35.052214Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8546</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>5250</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>6315</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>16096</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>10643</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15781</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>4673</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>12173</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>6996</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>1252</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18001 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                  inputs\n","8546   Instruction:\\n        Use the Task below and t...\n","5250   Instruction:\\n        Use the Task below and t...\n","6315   Instruction:\\n        Use the Task below and t...\n","16096  Instruction:\\n        Use the Task below and t...\n","10643  Instruction:\\n        Use the Task below and t...\n","...                                                  ...\n","15781  Instruction:\\n        Use the Task below and t...\n","4673   Instruction:\\n        Use the Task below and t...\n","12173  Instruction:\\n        Use the Task below and t...\n","6996   Instruction:\\n        Use the Task below and t...\n","1252   Instruction:\\n        Use the Task below and t...\n","\n","[18001 rows x 1 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["train_ds"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:44:52.209010Z","iopub.status.busy":"2024-04-04T06:44:52.208182Z","iopub.status.idle":"2024-04-04T06:44:52.219942Z","shell.execute_reply":"2024-04-04T06:44:52.218940Z","shell.execute_reply.started":"2024-04-04T06:44:52.208974Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11470</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>15254</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>10040</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>4858</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>8580</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11284</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>11964</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>5390</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","    <tr>\n","      <th>15795</th>\n","      <td>Instruction:\\n        Use the Task below and t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>611 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                  inputs\n","11470  Instruction:\\n        Use the Task below and t...\n","15254  Instruction:\\n        Use the Task below and t...\n","10040  Instruction:\\n        Use the Task below and t...\n","4858   Instruction:\\n        Use the Task below and t...\n","8580   Instruction:\\n        Use the Task below and t...\n","...                                                  ...\n","11284  Instruction:\\n        Use the Task below and t...\n","11964  Instruction:\\n        Use the Task below and t...\n","5390   Instruction:\\n        Use the Task below and t...\n","860    Instruction:\\n        Use the Task below and t...\n","15795  Instruction:\\n        Use the Task below and t...\n","\n","[611 rows x 1 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["test_ds"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T09:50:02.074739Z","iopub.status.busy":"2024-04-02T09:50:02.074451Z","iopub.status.idle":"2024-04-02T09:50:02.078901Z","shell.execute_reply":"2024-04-02T09:50:02.077960Z","shell.execute_reply.started":"2024-04-02T09:50:02.074714Z"},"trusted":true},"outputs":[],"source":["#val_ds = preprocess_function(dataset['validation'], tokenize=False, add_generation_prompt=False)\n","#val_ds\n","#frames = [train_ds, val_ds]\n","#train_ds = pd.concat(frames)\n","#train_ds"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:40:10.426490Z","iopub.status.busy":"2024-04-04T06:40:10.425493Z","iopub.status.idle":"2024-04-04T06:40:10.435140Z","shell.execute_reply":"2024-04-04T06:40:10.433799Z","shell.execute_reply.started":"2024-04-04T06:40:10.426444Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Instruction:\n","        Use the Task below and the Input given to write the Response, which is a programming code that can solve the following Task:\n","\n","        ### Task:\n","        Create a function to calculate the sum of a sequence of integers.\n","\n","        ### Input:\n","        [1, 2, 3, 4, 5]\n","\n","        ### Response:\n","        # Python code\n","def sum_sequence(sequence):\n","  sum = 0\n","  for num in sequence:\n","    sum += num\n","  return sum\n","        \n"]}],"source":["print(train_ds['inputs'][0])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:50:23.024931Z","iopub.status.busy":"2024-04-14T09:50:23.024652Z","iopub.status.idle":"2024-04-14T09:50:24.697619Z","shell.execute_reply":"2024-04-14T09:50:24.696631Z","shell.execute_reply.started":"2024-04-14T09:50:23.024883Z"},"trusted":true},"outputs":[],"source":["train_ds = pd.read_csv(\"/kaggle/input/tinycoder/train_dataset_python.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:50:24.699693Z","iopub.status.busy":"2024-04-14T09:50:24.698980Z","iopub.status.idle":"2024-04-14T09:50:24.792681Z","shell.execute_reply":"2024-04-14T09:50:24.791770Z","shell.execute_reply.started":"2024-04-14T09:50:24.699655Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['inputs'],\n","        num_rows: 18001\n","    })\n","})\n"]}],"source":["from datasets import DatasetDict\n","\n","\n","tdf = train_ds\n","#vdf = df_val\n","#testdf = test_ds\n","tds = Dataset.from_pandas(train_ds)\n","#vds = Dataset.from_pandas(vdf)\n","#testdf = Dataset.from_pandas(test_ds)\n","\n","\n","ds = DatasetDict()\n","\n","ds['train'] = tds\n","#ds['validation'] = vds\n","#ds['test'] = testdf\n","print(ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:43:12.466071Z","iopub.status.idle":"2024-04-02T09:43:12.466520Z","shell.execute_reply":"2024-04-02T09:43:12.466296Z","shell.execute_reply.started":"2024-04-02T09:43:12.466275Z"},"trusted":true},"outputs":[],"source":["#model, tokenizer = setup_chat_format(model, tokenizer, resize_to_multiple_of = 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:43:12.467650Z","iopub.status.idle":"2024-04-02T09:43:12.468072Z","shell.execute_reply":"2024-04-02T09:43:12.467874Z","shell.execute_reply.started":"2024-04-02T09:43:12.467854Z"},"trusted":true},"outputs":[],"source":["#special_tokens_dict = {'additional_special_tokens': ['<|user|>', \"<|assistant|>\"]}\n","#num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","#print('We have added', num_added_toks, 'tokens')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:51:33.258223Z","iopub.status.busy":"2024-04-14T09:51:33.257308Z","iopub.status.idle":"2024-04-14T09:51:33.264449Z","shell.execute_reply":"2024-04-14T09:51:33.263496Z","shell.execute_reply.started":"2024-04-14T09:51:33.258184Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['<|endoftext|>']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.all_special_tokens"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:51:33.421314Z","iopub.status.busy":"2024-04-14T09:51:33.420883Z","iopub.status.idle":"2024-04-14T09:51:33.427466Z","shell.execute_reply":"2024-04-14T09:51:33.426393Z","shell.execute_reply.started":"2024-04-14T09:51:33.421281Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2048"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = ds[\"train\"]"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:26:54.420323Z","iopub.status.busy":"2024-04-14T10:26:54.419923Z","iopub.status.idle":"2024-04-14T10:26:54.498309Z","shell.execute_reply":"2024-04-14T10:26:54.497532Z","shell.execute_reply.started":"2024-04-14T10:26:54.420295Z"},"trusted":true},"outputs":[],"source":["# Setting arguments for low-rank adaptation \n","\n","model = prepare_model_for_kbit_training(model)\n","\n","lora_alpha = 64 \n","lora_dropout = 0.01 \n","lora_rank = 64\n","\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    #target_modules=[ \"k_proj\", \"v_proj\", \"q_proj\"],\n","    r=lora_rank,\n","    bias=\"none\",  # setting to 'none' for only training weight params instead of biases\n","    task_type=\"CAUSAL_LM\")\n","\n","peft_model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:26:54.603891Z","iopub.status.busy":"2024-04-14T10:26:54.603595Z","iopub.status.idle":"2024-04-14T10:26:54.609985Z","shell.execute_reply":"2024-04-14T10:26:54.609074Z","shell.execute_reply.started":"2024-04-14T10:26:54.603865Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Salesforce/codegen-350M-mono'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["model_name "]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:26:54.781934Z","iopub.status.busy":"2024-04-14T10:26:54.781164Z","iopub.status.idle":"2024-04-14T10:26:54.811053Z","shell.execute_reply":"2024-04-14T10:26:54.810239Z","shell.execute_reply.started":"2024-04-14T10:26:54.781878Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n"]}],"source":["# Setting training arguments \n","output_dir = \"SSahas/codegen_e7\"\n","per_device_train_batch_size = 1\n","gradient_accumulation_steps = 1  \n","optim = \"paged_adamw_32bit\" \n","#optim = \"adamw_hf\"\n","num_train_epochs = 7\n","save_strategy=\"epoch\" \n","evaluation_strategy = 'steps'\n","#save_steps=\"epoch\"\n","#save_steps = 350 \n","#logging_steps = 200  \n","logging_strategy = 'steps'\n","learning_rate = 5e-4\n","#max_grad_norm = 0.3 # Sets limit for gradient clipping\n","#max_steps = 1500     # Number of training steps\n","#warmup_ratio = 0.03 # Portion of steps used for learning_rate to warmup from 0\n","lr_scheduler_type = \"cosine\" # I chose cosine to avoid learning plateaus\n","\n","training_arguments = TrainingArguments(\n","    #bf16 = True, \n","    fp16 = True,\n","    output_dir=output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    num_train_epochs=num_train_epochs,\n","    log_level=\"info\",\n","    save_strategy = save_strategy,\n","    logging_strategy = logging_strategy,\n","    #evaluation_strategy = evaluation_strategy,\n","    #save_steps=save_steps,\n","    #logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    #max_grad_norm=max_grad_norm,\n","    #max_steps=max_steps,\n","    #warmup_ratio=warmup_ratio,\n","    lr_scheduler_type=lr_scheduler_type,\n","    push_to_hub=False,\n","    report_to='none'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:26:55.263136Z","iopub.status.busy":"2024-04-14T10:26:55.262821Z","iopub.status.idle":"2024-04-14T10:27:01.276816Z","shell.execute_reply":"2024-04-14T10:27:01.275938Z","shell.execute_reply.started":"2024-04-14T10:26:55.263110Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c19536eb904b4f998c936bdac2d6a8ef","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/18001 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","Using auto half precision backend\n"]}],"source":["\n","trainer = SFTTrainer(\n","    model=peft_model,\n","    #model_init_kwargs=model_kwargs,\n","    #model_init_kwargs=model_kwargs,\n","    train_dataset=train_dataset,\n","    #eval_dataset = eval_dataset,\n","    peft_config=peft_config,\n","    max_seq_length=tokenizer.model_max_length,\n","    dataset_text_field='inputs',\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    #neftune_noise_alpha=5\n",")\n","#peft_model.config.use_cache = False"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:27:01.278636Z","iopub.status.busy":"2024-04-14T10:27:01.278340Z","iopub.status.idle":"2024-04-14T10:27:01.282851Z","shell.execute_reply":"2024-04-14T10:27:01.281863Z","shell.execute_reply.started":"2024-04-14T10:27:01.278610Z"},"trusted":true},"outputs":[],"source":["tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T10:27:01.284716Z","iopub.status.busy":"2024-04-14T10:27:01.284116Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 18,001\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 126,007\n","  Number of trainable parameters = 5,242,880\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='106482' max='126007' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [106482/126007 7:12:06 < 1:19:14, 4.11 it/s, Epoch 5.92/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.620200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.611000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.596100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.580300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.585700</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.614700</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.609800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.592000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.609800</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.592300</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.609600</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.583400</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.598000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.583400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.599800</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.587700</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.603200</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.590400</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.570600</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.594700</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.600700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.590000</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.606500</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.603200</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.589200</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.590400</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.591700</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.582600</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.599700</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.596900</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.599700</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.615300</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.590000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.611000</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.604400</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.596300</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.545500</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.550700</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.550500</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.557800</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.548400</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.557400</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.569000</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.575900</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.566500</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.564400</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.573400</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.567800</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.579400</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.569600</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.577700</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.594000</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.562500</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.569700</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>0.579200</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>0.575500</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>0.557700</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>0.570400</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>0.559500</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>0.555800</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>0.569700</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>0.580100</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>0.564700</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>0.585600</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>0.568300</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>0.572600</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>0.575300</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>0.580200</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>0.568000</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>0.557400</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>0.571000</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>0.577700</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>0.524200</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>0.513500</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>0.533200</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>0.521200</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>0.533400</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>0.537900</td>\n","    </tr>\n","    <tr>\n","      <td>39500</td>\n","      <td>0.517400</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>0.538000</td>\n","    </tr>\n","    <tr>\n","      <td>40500</td>\n","      <td>0.542200</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>0.521800</td>\n","    </tr>\n","    <tr>\n","      <td>41500</td>\n","      <td>0.537500</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>0.522900</td>\n","    </tr>\n","    <tr>\n","      <td>42500</td>\n","      <td>0.525700</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>0.530600</td>\n","    </tr>\n","    <tr>\n","      <td>43500</td>\n","      <td>0.522000</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>0.541100</td>\n","    </tr>\n","    <tr>\n","      <td>44500</td>\n","      <td>0.535500</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>0.521800</td>\n","    </tr>\n","    <tr>\n","      <td>45500</td>\n","      <td>0.538900</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>0.540800</td>\n","    </tr>\n","    <tr>\n","      <td>46500</td>\n","      <td>0.558100</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>0.531600</td>\n","    </tr>\n","    <tr>\n","      <td>47500</td>\n","      <td>0.508700</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>0.540100</td>\n","    </tr>\n","    <tr>\n","      <td>48500</td>\n","      <td>0.530000</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>0.536900</td>\n","    </tr>\n","    <tr>\n","      <td>49500</td>\n","      <td>0.542200</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>0.540000</td>\n","    </tr>\n","    <tr>\n","      <td>50500</td>\n","      <td>0.551000</td>\n","    </tr>\n","    <tr>\n","      <td>51000</td>\n","      <td>0.530600</td>\n","    </tr>\n","    <tr>\n","      <td>51500</td>\n","      <td>0.546100</td>\n","    </tr>\n","    <tr>\n","      <td>52000</td>\n","      <td>0.531600</td>\n","    </tr>\n","    <tr>\n","      <td>52500</td>\n","      <td>0.527900</td>\n","    </tr>\n","    <tr>\n","      <td>53000</td>\n","      <td>0.527900</td>\n","    </tr>\n","    <tr>\n","      <td>53500</td>\n","      <td>0.525400</td>\n","    </tr>\n","    <tr>\n","      <td>54000</td>\n","      <td>0.529100</td>\n","    </tr>\n","    <tr>\n","      <td>54500</td>\n","      <td>0.470700</td>\n","    </tr>\n","    <tr>\n","      <td>55000</td>\n","      <td>0.474800</td>\n","    </tr>\n","    <tr>\n","      <td>55500</td>\n","      <td>0.483000</td>\n","    </tr>\n","    <tr>\n","      <td>56000</td>\n","      <td>0.490000</td>\n","    </tr>\n","    <tr>\n","      <td>56500</td>\n","      <td>0.477600</td>\n","    </tr>\n","    <tr>\n","      <td>57000</td>\n","      <td>0.469800</td>\n","    </tr>\n","    <tr>\n","      <td>57500</td>\n","      <td>0.484400</td>\n","    </tr>\n","    <tr>\n","      <td>58000</td>\n","      <td>0.468900</td>\n","    </tr>\n","    <tr>\n","      <td>58500</td>\n","      <td>0.473500</td>\n","    </tr>\n","    <tr>\n","      <td>59000</td>\n","      <td>0.478600</td>\n","    </tr>\n","    <tr>\n","      <td>59500</td>\n","      <td>0.479500</td>\n","    </tr>\n","    <tr>\n","      <td>60000</td>\n","      <td>0.484500</td>\n","    </tr>\n","    <tr>\n","      <td>60500</td>\n","      <td>0.491800</td>\n","    </tr>\n","    <tr>\n","      <td>61000</td>\n","      <td>0.479500</td>\n","    </tr>\n","    <tr>\n","      <td>61500</td>\n","      <td>0.476900</td>\n","    </tr>\n","    <tr>\n","      <td>62000</td>\n","      <td>0.491200</td>\n","    </tr>\n","    <tr>\n","      <td>62500</td>\n","      <td>0.491500</td>\n","    </tr>\n","    <tr>\n","      <td>63000</td>\n","      <td>0.468300</td>\n","    </tr>\n","    <tr>\n","      <td>63500</td>\n","      <td>0.484900</td>\n","    </tr>\n","    <tr>\n","      <td>64000</td>\n","      <td>0.470700</td>\n","    </tr>\n","    <tr>\n","      <td>64500</td>\n","      <td>0.492700</td>\n","    </tr>\n","    <tr>\n","      <td>65000</td>\n","      <td>0.470600</td>\n","    </tr>\n","    <tr>\n","      <td>65500</td>\n","      <td>0.476100</td>\n","    </tr>\n","    <tr>\n","      <td>66000</td>\n","      <td>0.477200</td>\n","    </tr>\n","    <tr>\n","      <td>66500</td>\n","      <td>0.493900</td>\n","    </tr>\n","    <tr>\n","      <td>67000</td>\n","      <td>0.493000</td>\n","    </tr>\n","    <tr>\n","      <td>67500</td>\n","      <td>0.489500</td>\n","    </tr>\n","    <tr>\n","      <td>68000</td>\n","      <td>0.501200</td>\n","    </tr>\n","    <tr>\n","      <td>68500</td>\n","      <td>0.487000</td>\n","    </tr>\n","    <tr>\n","      <td>69000</td>\n","      <td>0.493600</td>\n","    </tr>\n","    <tr>\n","      <td>69500</td>\n","      <td>0.489300</td>\n","    </tr>\n","    <tr>\n","      <td>70000</td>\n","      <td>0.486600</td>\n","    </tr>\n","    <tr>\n","      <td>70500</td>\n","      <td>0.465500</td>\n","    </tr>\n","    <tr>\n","      <td>71000</td>\n","      <td>0.481600</td>\n","    </tr>\n","    <tr>\n","      <td>71500</td>\n","      <td>0.469200</td>\n","    </tr>\n","    <tr>\n","      <td>72000</td>\n","      <td>0.480900</td>\n","    </tr>\n","    <tr>\n","      <td>72500</td>\n","      <td>0.413200</td>\n","    </tr>\n","    <tr>\n","      <td>73000</td>\n","      <td>0.412600</td>\n","    </tr>\n","    <tr>\n","      <td>73500</td>\n","      <td>0.424900</td>\n","    </tr>\n","    <tr>\n","      <td>74000</td>\n","      <td>0.427100</td>\n","    </tr>\n","    <tr>\n","      <td>74500</td>\n","      <td>0.409500</td>\n","    </tr>\n","    <tr>\n","      <td>75000</td>\n","      <td>0.409700</td>\n","    </tr>\n","    <tr>\n","      <td>75500</td>\n","      <td>0.426100</td>\n","    </tr>\n","    <tr>\n","      <td>76000</td>\n","      <td>0.425500</td>\n","    </tr>\n","    <tr>\n","      <td>76500</td>\n","      <td>0.400300</td>\n","    </tr>\n","    <tr>\n","      <td>77000</td>\n","      <td>0.421200</td>\n","    </tr>\n","    <tr>\n","      <td>77500</td>\n","      <td>0.407100</td>\n","    </tr>\n","    <tr>\n","      <td>78000</td>\n","      <td>0.419200</td>\n","    </tr>\n","    <tr>\n","      <td>78500</td>\n","      <td>0.400900</td>\n","    </tr>\n","    <tr>\n","      <td>79000</td>\n","      <td>0.409900</td>\n","    </tr>\n","    <tr>\n","      <td>79500</td>\n","      <td>0.412200</td>\n","    </tr>\n","    <tr>\n","      <td>80000</td>\n","      <td>0.431400</td>\n","    </tr>\n","    <tr>\n","      <td>80500</td>\n","      <td>0.425800</td>\n","    </tr>\n","    <tr>\n","      <td>81000</td>\n","      <td>0.417300</td>\n","    </tr>\n","    <tr>\n","      <td>81500</td>\n","      <td>0.410100</td>\n","    </tr>\n","    <tr>\n","      <td>82000</td>\n","      <td>0.405000</td>\n","    </tr>\n","    <tr>\n","      <td>82500</td>\n","      <td>0.406300</td>\n","    </tr>\n","    <tr>\n","      <td>83000</td>\n","      <td>0.416100</td>\n","    </tr>\n","    <tr>\n","      <td>83500</td>\n","      <td>0.425700</td>\n","    </tr>\n","    <tr>\n","      <td>84000</td>\n","      <td>0.414200</td>\n","    </tr>\n","    <tr>\n","      <td>84500</td>\n","      <td>0.411900</td>\n","    </tr>\n","    <tr>\n","      <td>85000</td>\n","      <td>0.400200</td>\n","    </tr>\n","    <tr>\n","      <td>85500</td>\n","      <td>0.407600</td>\n","    </tr>\n","    <tr>\n","      <td>86000</td>\n","      <td>0.416000</td>\n","    </tr>\n","    <tr>\n","      <td>86500</td>\n","      <td>0.430200</td>\n","    </tr>\n","    <tr>\n","      <td>87000</td>\n","      <td>0.415500</td>\n","    </tr>\n","    <tr>\n","      <td>87500</td>\n","      <td>0.427200</td>\n","    </tr>\n","    <tr>\n","      <td>88000</td>\n","      <td>0.413500</td>\n","    </tr>\n","    <tr>\n","      <td>88500</td>\n","      <td>0.407200</td>\n","    </tr>\n","    <tr>\n","      <td>89000</td>\n","      <td>0.419600</td>\n","    </tr>\n","    <tr>\n","      <td>89500</td>\n","      <td>0.420100</td>\n","    </tr>\n","    <tr>\n","      <td>90000</td>\n","      <td>0.412500</td>\n","    </tr>\n","    <tr>\n","      <td>90500</td>\n","      <td>0.337800</td>\n","    </tr>\n","    <tr>\n","      <td>91000</td>\n","      <td>0.330500</td>\n","    </tr>\n","    <tr>\n","      <td>91500</td>\n","      <td>0.338400</td>\n","    </tr>\n","    <tr>\n","      <td>92000</td>\n","      <td>0.336700</td>\n","    </tr>\n","    <tr>\n","      <td>92500</td>\n","      <td>0.340900</td>\n","    </tr>\n","    <tr>\n","      <td>93000</td>\n","      <td>0.325300</td>\n","    </tr>\n","    <tr>\n","      <td>93500</td>\n","      <td>0.333700</td>\n","    </tr>\n","    <tr>\n","      <td>94000</td>\n","      <td>0.346200</td>\n","    </tr>\n","    <tr>\n","      <td>94500</td>\n","      <td>0.344700</td>\n","    </tr>\n","    <tr>\n","      <td>95000</td>\n","      <td>0.337700</td>\n","    </tr>\n","    <tr>\n","      <td>95500</td>\n","      <td>0.362100</td>\n","    </tr>\n","    <tr>\n","      <td>96000</td>\n","      <td>0.334500</td>\n","    </tr>\n","    <tr>\n","      <td>96500</td>\n","      <td>0.336100</td>\n","    </tr>\n","    <tr>\n","      <td>97000</td>\n","      <td>0.353200</td>\n","    </tr>\n","    <tr>\n","      <td>97500</td>\n","      <td>0.342500</td>\n","    </tr>\n","    <tr>\n","      <td>98000</td>\n","      <td>0.346100</td>\n","    </tr>\n","    <tr>\n","      <td>98500</td>\n","      <td>0.327300</td>\n","    </tr>\n","    <tr>\n","      <td>99000</td>\n","      <td>0.330300</td>\n","    </tr>\n","    <tr>\n","      <td>99500</td>\n","      <td>0.332700</td>\n","    </tr>\n","    <tr>\n","      <td>100000</td>\n","      <td>0.343800</td>\n","    </tr>\n","    <tr>\n","      <td>100500</td>\n","      <td>0.337700</td>\n","    </tr>\n","    <tr>\n","      <td>101000</td>\n","      <td>0.346500</td>\n","    </tr>\n","    <tr>\n","      <td>101500</td>\n","      <td>0.330300</td>\n","    </tr>\n","    <tr>\n","      <td>102000</td>\n","      <td>0.342400</td>\n","    </tr>\n","    <tr>\n","      <td>102500</td>\n","      <td>0.348500</td>\n","    </tr>\n","    <tr>\n","      <td>103000</td>\n","      <td>0.334000</td>\n","    </tr>\n","    <tr>\n","      <td>103500</td>\n","      <td>0.346200</td>\n","    </tr>\n","    <tr>\n","      <td>104000</td>\n","      <td>0.343300</td>\n","    </tr>\n","    <tr>\n","      <td>104500</td>\n","      <td>0.335000</td>\n","    </tr>\n","    <tr>\n","      <td>105000</td>\n","      <td>0.331800</td>\n","    </tr>\n","    <tr>\n","      <td>105500</td>\n","      <td>0.350200</td>\n","    </tr>\n","    <tr>\n","      <td>106000</td>\n","      <td>0.331700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to SSahas/codegen_e7/tmp-checkpoint-18001\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer config file saved in SSahas/codegen_e7/tmp-checkpoint-18001/tokenizer_config.json\n","Special tokens file saved in SSahas/codegen_e7/tmp-checkpoint-18001/special_tokens_map.json\n","Saving model checkpoint to SSahas/codegen_e7/tmp-checkpoint-36002\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer config file saved in SSahas/codegen_e7/tmp-checkpoint-36002/tokenizer_config.json\n","Special tokens file saved in SSahas/codegen_e7/tmp-checkpoint-36002/special_tokens_map.json\n","Saving model checkpoint to SSahas/codegen_e7/tmp-checkpoint-54003\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer config file saved in SSahas/codegen_e7/tmp-checkpoint-54003/tokenizer_config.json\n","Special tokens file saved in SSahas/codegen_e7/tmp-checkpoint-54003/special_tokens_map.json\n","Saving model checkpoint to SSahas/codegen_e7/tmp-checkpoint-72004\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer config file saved in SSahas/codegen_e7/tmp-checkpoint-72004/tokenizer_config.json\n","Special tokens file saved in SSahas/codegen_e7/tmp-checkpoint-72004/special_tokens_map.json\n","Saving model checkpoint to SSahas/codegen_e7/tmp-checkpoint-90005\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\n","Model config CodeGenConfig {\n","  \"_name_or_path\": \"codegen-350M-mono\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"CodeGenForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"codegen\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 20,\n","  \"n_positions\": 2048,\n","  \"resid_pdrop\": 0.0,\n","  \"rotary_dim\": 32,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"temperature\": 1.0\n","    }\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"GPT2Tokenizer\",\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer config file saved in SSahas/codegen_e7/tmp-checkpoint-90005/tokenizer_config.json\n","Special tokens file saved in SSahas/codegen_e7/tmp-checkpoint-90005/special_tokens_map.json\n"]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4749561,"sourceId":8053372,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
