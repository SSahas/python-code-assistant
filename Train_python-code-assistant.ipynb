{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install trl peft datasets -Uqqq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-29T10:14:31.649909Z","iopub.execute_input":"2024-08-29T10:14:31.650353Z","iopub.status.idle":"2024-08-29T10:14:47.218037Z","shell.execute_reply.started":"2024-08-29T10:14:31.650316Z","shell.execute_reply":"2024-08-29T10:14:47.216825Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import get_peft_model, PeftConfig, PeftModel, LoraConfig\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, GenerationConfig, BitsAndBytesConfig\nfrom trl import SFTTrainer\nfrom datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:14:58.268904Z","iopub.execute_input":"2024-08-29T10:14:58.269291Z","iopub.status.idle":"2024-08-29T10:15:17.403851Z","shell.execute_reply.started":"2024-08-29T10:14:58.269252Z","shell.execute_reply":"2024-08-29T10:15:17.403086Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom trl import SFTConfig, SFTTrainer\nfrom peft import LoraConfig\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:15:17.405463Z","iopub.execute_input":"2024-08-29T10:15:17.406055Z","iopub.status.idle":"2024-08-29T10:15:17.410653Z","shell.execute_reply.started":"2024-08-29T10:15:17.406019Z","shell.execute_reply":"2024-08-29T10:15:17.409628Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#quantization_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_quant_type=\"nf4\",bnb_4bit_use_double_quant=False, bnb_4bit_compute_dtype=torch.bfloat16)\n\nmodel_name = \"Salesforce/codegen-350M-mono\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    #quantization_config=quantization_config, \n    device_map=\"auto\",  \n    trust_remote_code=True,\n    \n)\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True) ","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:01.436586Z","iopub.execute_input":"2024-08-29T10:16:01.436989Z","iopub.status.idle":"2024-08-29T10:16:08.664301Z","shell.execute_reply.started":"2024-08-29T10:16:01.436951Z","shell.execute_reply":"2024-08-29T10:16:08.663342Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb196106773749919b27d5d78fdbd40e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/797M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ee5fd515da4f55b138e92b319cdc41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba03e81d01914b64a7ae05edd8a08b42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a848da1ebf4483b4d927fe850b0d7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a02e58ca044f2381aa79c5b2791124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d607d40c1ed49bdab55971be946b92e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81ea65d834ee48a0aec31b66a53774e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab4a02d9f5454e3d888f52641ff5ac01"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"if tokenizer.model_max_length > 100_000:\n    tokenizer.model_max_length = 2048","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:12.968478Z","iopub.execute_input":"2024-08-29T10:16:12.969499Z","iopub.status.idle":"2024-08-29T10:16:12.974104Z","shell.execute_reply.started":"2024-08-29T10:16:12.969443Z","shell.execute_reply":"2024-08-29T10:16:12.973186Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:14.071375Z","iopub.execute_input":"2024-08-29T10:16:14.072004Z","iopub.status.idle":"2024-08-29T10:16:15.433931Z","shell.execute_reply.started":"2024-08-29T10:16:14.071964Z","shell.execute_reply":"2024-08-29T10:16:15.432946Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-28T14:59:14.891347Z","iopub.execute_input":"2024-08-28T14:59:14.891737Z","iopub.status.idle":"2024-08-28T14:59:14.896456Z","shell.execute_reply.started":"2024-08-28T14:59:14.891701Z","shell.execute_reply":"2024-08-28T14:59:14.895562Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:18.231640Z","iopub.execute_input":"2024-08-29T10:16:18.232409Z","iopub.status.idle":"2024-08-29T10:16:21.466023Z","shell.execute_reply.started":"2024-08-29T10:16:18.232366Z","shell.execute_reply":"2024-08-29T10:16:21.465142Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/905 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166e2ad3328244b1a8abc0d70fe5a32e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7396160b30412a8df0f5ecd488da4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/18612 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98318f0d169c4f189c41c6b7ee3ebe0e"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'input', 'output', 'prompt'],\n        num_rows: 18612\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def add_eos_token(sample):\n    \n    sample['prompt'] = tokenizer.bos_token + sample['prompt'] + tokenizer.eos_token\n    return sample\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:26.782604Z","iopub.execute_input":"2024-08-29T10:16:26.782997Z","iopub.status.idle":"2024-08-29T10:16:26.788001Z","shell.execute_reply.started":"2024-08-29T10:16:26.782958Z","shell.execute_reply":"2024-08-29T10:16:26.786959Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(add_eos_token, load_from_cache_file = False)\nprint(dataset['train']['prompt'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:33.792663Z","iopub.execute_input":"2024-08-29T10:16:33.793056Z","iopub.status.idle":"2024-08-29T10:16:35.426068Z","shell.execute_reply.started":"2024-08-29T10:16:33.793018Z","shell.execute_reply":"2024-08-29T10:16:35.425188Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18612 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8f6cf920cef47bd9d699c3e63e3a65d"}},"metadata":{}},{"name":"stdout","text":"<|endoftext|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nCreate a function to calculate the sum of a sequence of integers.\n\n### Input:\n[1, 2, 3, 4, 5]\n\n### Output:\n# Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum<|endoftext|>\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = dataset['train'].train_test_split(test_size = 0.08, seed = 42)\ndataset \n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:38.743837Z","iopub.execute_input":"2024-08-29T10:16:38.744245Z","iopub.status.idle":"2024-08-29T10:16:38.810420Z","shell.execute_reply.started":"2024-08-29T10:16:38.744207Z","shell.execute_reply":"2024-08-29T10:16:38.809465Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'input', 'output', 'prompt'],\n        num_rows: 17123\n    })\n    test: Dataset({\n        features: ['instruction', 'input', 'output', 'prompt'],\n        num_rows: 1489\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    #bf16 = True, \n    fp16 = True,\n    output_dir=\"/kaggle/working/\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=1,\n    #optim=\"paged_adamw_32bit\" ,\n    num_train_epochs=6,\n    log_level=\"info\",\n    save_strategy = 'epoch',\n    logging_strategy = 'steps',\n    #evaluation_strategy = evaluation_strategy,\n    #save_steps=save_steps,\n    #logging_steps=logging_steps,\n    learning_rate=5e-4,\n    #max_grad_norm=max_grad_norm,\n    #max_steps=max_steps,\n    #warmup_ratio=warmup_ratio,\n    #lr_scheduler_type='cosine',\n    push_to_hub=False,\n    report_to='none'\n)\n\n\npeft_config = LoraConfig(\n    r=32,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\ntrainer = SFTTrainer(\n    model = model,\n    train_dataset=dataset['train'],\n    #args=SFTConfig(output_dir=\"/tmp\"),\n    peft_config=peft_config,\n    dataset_text_field = 'prompt',\n    max_seq_length = 2048,\n    args = training_arguments,\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T10:16:56.575259Z","iopub.execute_input":"2024-08-29T10:16:56.575639Z","iopub.status.idle":"2024-08-29T13:53:28.565003Z","shell.execute_reply.started":"2024-08-29T10:16:56.575603Z","shell.execute_reply":"2024-08-29T13:53:28.564103Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/17123 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb03d283bcba47aa8531a5719be8caa5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nUsing auto half precision backend\n***** Running training *****\n  Num examples = 17,123\n  Num Epochs = 6\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 1\n  Gradient Accumulation steps = 1\n  Total optimization steps = 102,738\n  Number of trainable parameters = 2,621,440\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='102738' max='102738' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [102738/102738 3:36:24, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.668200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.637100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.629500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.625100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.636300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.629500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.618900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.633700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.636000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.613300</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.607500</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.607300</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.609400</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.600000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.620800</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.609000</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.617900</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.605600</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.635000</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.604500</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.619000</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.608700</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.621900</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.616700</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.599100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.610300</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.599100</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.608700</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.604300</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.622300</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.597900</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.579900</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.614900</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.629100</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.582300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.573400</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.571200</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.565200</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.577200</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.572900</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.571700</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.572500</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>0.569200</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.574200</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>0.567100</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.569400</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>0.591200</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.578500</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>0.571800</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>0.580800</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>0.574100</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>0.571500</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>0.574800</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>0.575800</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>0.564100</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>0.559700</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>0.572800</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>0.578900</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>0.587300</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>0.583800</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>0.586100</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>0.583400</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>0.580500</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>0.558700</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>0.575000</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>0.567000</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>0.585700</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>0.583900</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>0.531300</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>0.520400</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>0.535500</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>0.526100</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>0.537600</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>0.532600</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>0.528300</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>0.558500</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>0.523400</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>0.532400</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>0.519700</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>0.515800</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>0.545900</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>0.545500</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>0.542400</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>0.562300</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>0.530700</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>0.537100</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>0.537700</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>0.557100</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>0.528500</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>0.542400</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>0.536800</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>0.551000</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>0.551600</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>0.542300</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>0.529600</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>0.544100</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>0.546700</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>0.525100</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>0.540700</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>0.531600</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>0.535600</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>0.507900</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>0.490700</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>0.501700</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>0.493800</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>0.487800</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>0.476100</td>\n    </tr>\n    <tr>\n      <td>54500</td>\n      <td>0.484300</td>\n    </tr>\n    <tr>\n      <td>55000</td>\n      <td>0.495100</td>\n    </tr>\n    <tr>\n      <td>55500</td>\n      <td>0.478600</td>\n    </tr>\n    <tr>\n      <td>56000</td>\n      <td>0.491300</td>\n    </tr>\n    <tr>\n      <td>56500</td>\n      <td>0.486700</td>\n    </tr>\n    <tr>\n      <td>57000</td>\n      <td>0.490400</td>\n    </tr>\n    <tr>\n      <td>57500</td>\n      <td>0.498200</td>\n    </tr>\n    <tr>\n      <td>58000</td>\n      <td>0.496500</td>\n    </tr>\n    <tr>\n      <td>58500</td>\n      <td>0.506100</td>\n    </tr>\n    <tr>\n      <td>59000</td>\n      <td>0.500400</td>\n    </tr>\n    <tr>\n      <td>59500</td>\n      <td>0.500500</td>\n    </tr>\n    <tr>\n      <td>60000</td>\n      <td>0.486700</td>\n    </tr>\n    <tr>\n      <td>60500</td>\n      <td>0.488600</td>\n    </tr>\n    <tr>\n      <td>61000</td>\n      <td>0.495500</td>\n    </tr>\n    <tr>\n      <td>61500</td>\n      <td>0.491300</td>\n    </tr>\n    <tr>\n      <td>62000</td>\n      <td>0.515400</td>\n    </tr>\n    <tr>\n      <td>62500</td>\n      <td>0.499100</td>\n    </tr>\n    <tr>\n      <td>63000</td>\n      <td>0.490000</td>\n    </tr>\n    <tr>\n      <td>63500</td>\n      <td>0.496500</td>\n    </tr>\n    <tr>\n      <td>64000</td>\n      <td>0.483700</td>\n    </tr>\n    <tr>\n      <td>64500</td>\n      <td>0.487100</td>\n    </tr>\n    <tr>\n      <td>65000</td>\n      <td>0.508100</td>\n    </tr>\n    <tr>\n      <td>65500</td>\n      <td>0.501000</td>\n    </tr>\n    <tr>\n      <td>66000</td>\n      <td>0.490200</td>\n    </tr>\n    <tr>\n      <td>66500</td>\n      <td>0.504800</td>\n    </tr>\n    <tr>\n      <td>67000</td>\n      <td>0.515200</td>\n    </tr>\n    <tr>\n      <td>67500</td>\n      <td>0.489200</td>\n    </tr>\n    <tr>\n      <td>68000</td>\n      <td>0.493400</td>\n    </tr>\n    <tr>\n      <td>68500</td>\n      <td>0.485200</td>\n    </tr>\n    <tr>\n      <td>69000</td>\n      <td>0.421200</td>\n    </tr>\n    <tr>\n      <td>69500</td>\n      <td>0.462100</td>\n    </tr>\n    <tr>\n      <td>70000</td>\n      <td>0.423700</td>\n    </tr>\n    <tr>\n      <td>70500</td>\n      <td>0.452200</td>\n    </tr>\n    <tr>\n      <td>71000</td>\n      <td>0.449300</td>\n    </tr>\n    <tr>\n      <td>71500</td>\n      <td>0.454900</td>\n    </tr>\n    <tr>\n      <td>72000</td>\n      <td>0.437400</td>\n    </tr>\n    <tr>\n      <td>72500</td>\n      <td>0.455600</td>\n    </tr>\n    <tr>\n      <td>73000</td>\n      <td>0.450300</td>\n    </tr>\n    <tr>\n      <td>73500</td>\n      <td>0.449400</td>\n    </tr>\n    <tr>\n      <td>74000</td>\n      <td>0.439000</td>\n    </tr>\n    <tr>\n      <td>74500</td>\n      <td>0.437600</td>\n    </tr>\n    <tr>\n      <td>75000</td>\n      <td>0.444800</td>\n    </tr>\n    <tr>\n      <td>75500</td>\n      <td>0.449100</td>\n    </tr>\n    <tr>\n      <td>76000</td>\n      <td>0.441400</td>\n    </tr>\n    <tr>\n      <td>76500</td>\n      <td>0.466100</td>\n    </tr>\n    <tr>\n      <td>77000</td>\n      <td>0.448700</td>\n    </tr>\n    <tr>\n      <td>77500</td>\n      <td>0.450700</td>\n    </tr>\n    <tr>\n      <td>78000</td>\n      <td>0.437100</td>\n    </tr>\n    <tr>\n      <td>78500</td>\n      <td>0.452600</td>\n    </tr>\n    <tr>\n      <td>79000</td>\n      <td>0.454300</td>\n    </tr>\n    <tr>\n      <td>79500</td>\n      <td>0.444000</td>\n    </tr>\n    <tr>\n      <td>80000</td>\n      <td>0.446900</td>\n    </tr>\n    <tr>\n      <td>80500</td>\n      <td>0.448100</td>\n    </tr>\n    <tr>\n      <td>81000</td>\n      <td>0.466500</td>\n    </tr>\n    <tr>\n      <td>81500</td>\n      <td>0.447600</td>\n    </tr>\n    <tr>\n      <td>82000</td>\n      <td>0.451700</td>\n    </tr>\n    <tr>\n      <td>82500</td>\n      <td>0.444800</td>\n    </tr>\n    <tr>\n      <td>83000</td>\n      <td>0.446800</td>\n    </tr>\n    <tr>\n      <td>83500</td>\n      <td>0.442900</td>\n    </tr>\n    <tr>\n      <td>84000</td>\n      <td>0.454400</td>\n    </tr>\n    <tr>\n      <td>84500</td>\n      <td>0.448100</td>\n    </tr>\n    <tr>\n      <td>85000</td>\n      <td>0.434400</td>\n    </tr>\n    <tr>\n      <td>85500</td>\n      <td>0.442600</td>\n    </tr>\n    <tr>\n      <td>86000</td>\n      <td>0.416900</td>\n    </tr>\n    <tr>\n      <td>86500</td>\n      <td>0.398300</td>\n    </tr>\n    <tr>\n      <td>87000</td>\n      <td>0.388500</td>\n    </tr>\n    <tr>\n      <td>87500</td>\n      <td>0.394400</td>\n    </tr>\n    <tr>\n      <td>88000</td>\n      <td>0.403200</td>\n    </tr>\n    <tr>\n      <td>88500</td>\n      <td>0.390700</td>\n    </tr>\n    <tr>\n      <td>89000</td>\n      <td>0.414500</td>\n    </tr>\n    <tr>\n      <td>89500</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <td>90000</td>\n      <td>0.385300</td>\n    </tr>\n    <tr>\n      <td>90500</td>\n      <td>0.415000</td>\n    </tr>\n    <tr>\n      <td>91000</td>\n      <td>0.394000</td>\n    </tr>\n    <tr>\n      <td>91500</td>\n      <td>0.388300</td>\n    </tr>\n    <tr>\n      <td>92000</td>\n      <td>0.393100</td>\n    </tr>\n    <tr>\n      <td>92500</td>\n      <td>0.407100</td>\n    </tr>\n    <tr>\n      <td>93000</td>\n      <td>0.379500</td>\n    </tr>\n    <tr>\n      <td>93500</td>\n      <td>0.404200</td>\n    </tr>\n    <tr>\n      <td>94000</td>\n      <td>0.401800</td>\n    </tr>\n    <tr>\n      <td>94500</td>\n      <td>0.398400</td>\n    </tr>\n    <tr>\n      <td>95000</td>\n      <td>0.398700</td>\n    </tr>\n    <tr>\n      <td>95500</td>\n      <td>0.401400</td>\n    </tr>\n    <tr>\n      <td>96000</td>\n      <td>0.393200</td>\n    </tr>\n    <tr>\n      <td>96500</td>\n      <td>0.405600</td>\n    </tr>\n    <tr>\n      <td>97000</td>\n      <td>0.405700</td>\n    </tr>\n    <tr>\n      <td>97500</td>\n      <td>0.393600</td>\n    </tr>\n    <tr>\n      <td>98000</td>\n      <td>0.389600</td>\n    </tr>\n    <tr>\n      <td>98500</td>\n      <td>0.390800</td>\n    </tr>\n    <tr>\n      <td>99000</td>\n      <td>0.408900</td>\n    </tr>\n    <tr>\n      <td>99500</td>\n      <td>0.399300</td>\n    </tr>\n    <tr>\n      <td>100000</td>\n      <td>0.401000</td>\n    </tr>\n    <tr>\n      <td>100500</td>\n      <td>0.385600</td>\n    </tr>\n    <tr>\n      <td>101000</td>\n      <td>0.386600</td>\n    </tr>\n    <tr>\n      <td>101500</td>\n      <td>0.408800</td>\n    </tr>\n    <tr>\n      <td>102000</td>\n      <td>0.383800</td>\n    </tr>\n    <tr>\n      <td>102500</td>\n      <td>0.395800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-17123\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-17123/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-17123/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-34246\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-34246/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-34246/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-51369\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-51369/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-51369/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-68492\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-68492/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-68492/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-85615\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-85615/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-85615/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-102738\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-102738/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-102738/special_tokens_map.json\nSaving model checkpoint to /kaggle/working/checkpoint-102738\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/checkpoint-102738/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-102738/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=102738, training_loss=0.5109873899043125, metrics={'train_runtime': 12985.3821, 'train_samples_per_second': 7.912, 'train_steps_per_second': 7.912, 'total_flos': 4.031139650627174e+16, 'train_loss': 0.5109873899043125, 'epoch': 6.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"salesforce_codegen\"\n\n\ntrainer.save_model(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:01:35.437162Z","iopub.execute_input":"2024-08-29T14:01:35.438194Z","iopub.status.idle":"2024-08-29T14:01:35.753009Z","shell.execute_reply.started":"2024-08-29T14:01:35.438151Z","shell.execute_reply":"2024-08-29T14:01:35.752261Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Saving model checkpoint to salesforce_codegen\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in salesforce_codegen/tokenizer_config.json\nSpecial tokens file saved in salesforce_codegen/special_tokens_map.json\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_testdata(example):\n\n    index = example['prompt'].find(\"### Output:\")\n    example['test_input'] = example['prompt'][0: index + 11]\n\n    example['test_output'] = example['prompt'][index + 11:]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:02:01.738607Z","iopub.execute_input":"2024-08-29T14:02:01.739006Z","iopub.status.idle":"2024-08-29T14:02:01.744212Z","shell.execute_reply.started":"2024-08-29T14:02:01.738967Z","shell.execute_reply":"2024-08-29T14:02:01.743330Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset['test'] = dataset['test'].map(process_testdata)\ndataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:02:20.784407Z","iopub.execute_input":"2024-08-29T14:02:20.784785Z","iopub.status.idle":"2024-08-29T14:02:21.011893Z","shell.execute_reply.started":"2024-08-29T14:02:20.784748Z","shell.execute_reply":"2024-08-29T14:02:21.011065Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1489 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35276f6d9b446b4b45b422c99ecff31"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'prompt', 'test_input', 'test_output'],\n    num_rows: 1489\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub -Uqqq\nfrom huggingface_hub import notebook_login\n\nnotebook_login()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:03:52.858380Z","iopub.execute_input":"2024-08-29T14:03:52.858757Z","iopub.status.idle":"2024-08-29T14:04:06.112906Z","shell.execute_reply.started":"2024-08-29T14:03:52.858719Z","shell.execute_reply":"2024-08-29T14:04:06.111920Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"207be3b6a0804b008724383e274090e4"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"SSahas/python_code_assistant\")","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:05:21.871972Z","iopub.execute_input":"2024-08-29T14:05:21.872385Z","iopub.status.idle":"2024-08-29T14:05:26.190864Z","shell.execute_reply.started":"2024-08-29T14:05:21.872345Z","shell.execute_reply":"2024-08-29T14:05:26.189952Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\ntokenizer config file saved in /kaggle/working/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/special_tokens_map.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/10.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996d2bfa68ff431fabaca97317a3ea0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783a536b930e4745afde63cc18d93fcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/10.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f883ffde9e43fcbd27dbca44e5a361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d47c243a1b842f1a46eb40046a8af43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b5ddad5bc3d4abf86f4e555408947e3"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/SSahas/working/commit/53f4c180262ef8230911b4c2b076535174ccbba1', commit_message='SSahas/python_code_assistant', commit_description='', oid='53f4c180262ef8230911b4c2b076535174ccbba1', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM\n\nconfig = PeftConfig.from_pretrained(\"SSahas/working\")\nbase_model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")\nmodel = PeftModel.from_pretrained(base_model, \"SSahas/working\")\ntokenizer = AutoTokenizer.from_pretrained(\"SSahas/working\")","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:06:25.861264Z","iopub.execute_input":"2024-08-29T14:06:25.861994Z","iopub.status.idle":"2024-08-29T14:06:30.280078Z","shell.execute_reply.started":"2024-08-29T14:06:25.861955Z","shell.execute_reply":"2024-08-29T14:06:30.279369Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08aad349d68a4f06bca32cc535e054d4"}},"metadata":{}},{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/config.json\nModel config CodeGenConfig {\n  \"_name_or_path\": \"Salesforce/codegen-350M-mono\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"CodeGenForCausalLM\"\n  ],\n  \"attn_pdrop\": 0.0,\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"codegen\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 1024,\n  \"n_head\": 16,\n  \"n_inner\": null,\n  \"n_layer\": 20,\n  \"n_positions\": 2048,\n  \"resid_pdrop\": 0.0,\n  \"rotary_dim\": 32,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50,\n      \"temperature\": 1.0\n    }\n  },\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"GPT2Tokenizer\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.44.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 51200\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-mono/snapshots/40b7a3b6e99e73bdb497a14b740e7167b3413c74/pytorch_model.bin\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 50256\n}\n\nAll model checkpoint weights were used when initializing CodeGenForCausalLM.\n\nAll the weights of CodeGenForCausalLM were initialized from the model checkpoint at Salesforce/codegen-350M-mono.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use CodeGenForCausalLM for predictions without further training.\nGeneration config file not found, using a generation config created from the model config.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/10.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defa06885a9d4ebd89eaddbaca2e193c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e6890fb6c9493f8a7cdd66c721886b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5947893cfbc4fc1a88c487414e27afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a0e89f602f41d4aea2567fda068e0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e743402c04bd48ddadf3293804a572c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ac31478fe3840239b6dd190ca509008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1106311102fb4c07a6675bc012f3b743"}},"metadata":{}},{"name":"stderr","text":"loading file vocab.json from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/tokenizer.json\nloading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/added_tokens.json\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--SSahas--working/snapshots/53f4c180262ef8230911b4c2b076535174ccbba1/tokenizer_config.json\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_code(input_text):\n\n\n    input_ids = tokenizer(input_text, padding = False, return_tensors = \"pt\")\n\n    output = model.generate(input_ids=input_ids['input_ids'], attention_mask = input_ids[\"attention_mask\"] , generation_config=GenerationConfig(max_new_tokens =  256, eos_token_id = 50256, pad_token_id = 50256))\n    output = tokenizer.decode(output[0], skip_special_tokens=False) #original\n\n    #generated_code = output[0:output.find(\"Output\")]\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:14:10.764748Z","iopub.execute_input":"2024-08-29T14:14:10.765165Z","iopub.status.idle":"2024-08-29T14:14:10.771424Z","shell.execute_reply.started":"2024-08-29T14:14:10.765119Z","shell.execute_reply":"2024-08-29T14:14:10.770390Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(generate_code(dataset['test'][3]['test_input']))","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:14:11.083848Z","iopub.execute_input":"2024-08-29T14:14:11.084807Z","iopub.status.idle":"2024-08-29T14:14:34.305982Z","shell.execute_reply.started":"2024-08-29T14:14:11.084766Z","shell.execute_reply":"2024-08-29T14:14:34.305016Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"<|endoftext|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nCreate a cloud-based web service in Python that takes a JSON input and returns the data ready for visualization.\n\n### Input:\n[\n  { date: '2016-01-01', sales: 50 },\n  { date: '2016-02-01', sales: 70 },\n  { date: '2016-03-01', sales: 100 }\n]\n\n### Output:\nimport json\nimport flask\nfrom flask import request, jsonify\n\n# Create the app\napp = flask.Flask(__name__)\n\n# Create a database\ndb = []\n\n# Create a function to get the data\n@app.route('/data', methods=['GET'])\ndef get_data():\n    # Get the data from the query string\n    date = request.args.get('date')\n    sales = request.args.get('sales')\n\n    # Convert the data to a list\n    data = [{'date': date,'sales': sales}]\n\n    # Return the data\n    return jsonify(data)\n\n# Run the app\nif __name__ == '__main__':\n    app.run(debug=True)\n\n# Output:\n{\n 'date': '2016-01-01',\n'sales': 50\n}\n\n# Output:\n{\n 'date': '2016-02-01',\n'sales': 70\n}\n\n# Output:\n{\n 'date': '2016-03-01',\n'sales': 100\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset['test'][3]['prompt'])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:12:31.442017Z","iopub.execute_input":"2024-08-29T14:12:31.442406Z","iopub.status.idle":"2024-08-29T14:12:31.447927Z","shell.execute_reply.started":"2024-08-29T14:12:31.442370Z","shell.execute_reply":"2024-08-29T14:12:31.447013Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"<|endoftext|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nCreate a cloud-based web service in Python that takes a JSON input and returns the data ready for visualization.\n\n### Input:\n[\n  { date: '2016-01-01', sales: 50 },\n  { date: '2016-02-01', sales: 70 },\n  { date: '2016-03-01', sales: 100 }\n]\n\n### Output:\nimport json\nfrom flask import Flask, request\n\n# Create Flask object\napp = Flask(__name__)\n\n# POST route for request\n@app.route('/', methods=['POST'])\ndef handlePost(): \n # Get data from request object\n data = request.get_json()\n\n # Manipulate data for visualization\n res = {\n 'dates': [],\n 'sales': []\n }\n for datum in data:\n res['dates'].append(datum['date'])\n res['sales'].append(datum['sales'])\n\n # Return data\n return json.dumps(res)\n\nif __name__ == '__main__':\n app.run(host='0.0.0.0', port=PORT)<|endoftext|>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#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","metadata":{},"execution_count":null,"outputs":[]}]}
